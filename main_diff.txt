diff --git a/package-lock.json b/package-lock.json
index 644e5e9..1c94b0a 100644
--- a/package-lock.json
+++ b/package-lock.json
@@ -18,7 +18,6 @@
         "@testing-library/react": "^13.4.0",
         "@testing-library/user-event": "^13.5.0",
         "@xzdarcy/react-timeline-editor": "^0.1.9",
-        "axios": "^1.7.7",
         "debug": "^4.3.7",
         "lucide-react": "^0.453.0",
         "react": "^18.3.1",
@@ -5846,29 +5845,6 @@
         "node": ">=4"
       }
     },
-    "node_modules/axios": {
-      "version": "1.7.7",
-      "resolved": "https://registry.npmjs.org/axios/-/axios-1.7.7.tgz",
-      "integrity": "sha512-S4kL7XrjgBmvdGut0sN3yJxqYzrDOnivkBiN0OFs6hLiUam3UPvswUo0kqGyhqUZGEOytHyumEdXsAkgCOUf3Q==",
-      "dependencies": {
-        "follow-redirects": "^1.15.6",
-        "form-data": "^4.0.0",
-        "proxy-from-env": "^1.1.0"
-      }
-    },
-    "node_modules/axios/node_modules/form-data": {
-      "version": "4.0.1",
-      "resolved": "https://registry.npmjs.org/form-data/-/form-data-4.0.1.tgz",
-      "integrity": "sha512-tzN8e4TX8+kkxGPK8D5u0FNmjPUjw3lwC9lSLxxoB/+GtsJG91CO8bSWy73APlgAZzZbXEYZJuxjkHH2w+Ezhw==",
-      "dependencies": {
-        "asynckit": "^0.4.0",
-        "combined-stream": "^1.0.8",
-        "mime-types": "^2.1.12"
-      },
-      "engines": {
-        "node": ">= 6"
-      }
-    },
     "node_modules/axobject-query": {
       "version": "4.1.0",
       "resolved": "https://registry.npmjs.org/axobject-query/-/axobject-query-4.1.0.tgz",
@@ -15186,11 +15162,6 @@
         "node": ">= 0.10"
       }
     },
-    "node_modules/proxy-from-env": {
-      "version": "1.1.0",
-      "resolved": "https://registry.npmjs.org/proxy-from-env/-/proxy-from-env-1.1.0.tgz",
-      "integrity": "sha512-D+zkORCbA9f1tdWRK0RaCR3GPv50cMxcrz4X8k5LTSUD1Dkw47mKJEZQNunItRTkWwgtaUSo1RVFRIG9ZXiFYg=="
-    },
     "node_modules/psl": {
       "version": "1.9.0",
       "resolved": "https://registry.npmjs.org/psl/-/psl-1.9.0.tgz",
diff --git a/package.json b/package.json
index f221851..0b014b4 100644
--- a/package.json
+++ b/package.json
@@ -13,7 +13,6 @@
     "@testing-library/react": "^13.4.0",
     "@testing-library/user-event": "^13.5.0",
     "@xzdarcy/react-timeline-editor": "^0.1.9",
-    "axios": "^1.7.7",
     "debug": "^4.3.7",
     "lucide-react": "^0.453.0",
     "react": "^18.3.1",
diff --git a/src/App.js b/src/App.js
index 8cf653d..c2a581d 100644
--- a/src/App.js
+++ b/src/App.js
@@ -7,9 +7,6 @@ import { Box, Snackbar, Alert } from '@mui/material';
 import MainLayout from './components/Layout/MainLayout';
 import EditorLayout from './components/Layout/EditorLayout';
 
-// Chabot
-import ChatBot from './components/Chatbot/ChatBot';
-
 // Viewer components
 import BinViewerSection from './components/Viewers/BinViewerSection';
 import TimelineViewerSection from './components/Viewers/TimelineViewerSection';
@@ -39,15 +36,6 @@ function App() {
   const [selectedTimelineProject, setSelectedTimelineProject] = useState(null);
   const [transcripts, setTranscripts] = useState(new Map());
 
-  const [chatMessages, setChatMessages] = useState([]);
-
-// Add this handler function:
-const handleChatMessage = (message) => {
-  setChatMessages(prev => [...prev, message]);
-};
-
-
-
   // Timeline metadata state
   const [timelineMetadata, setTimelineMetadata] = useState({
     scale: 1,
@@ -150,19 +138,12 @@ const handleChatMessage = (message) => {
     const transcriptName = clipData.name.replace(/\.[^/.]+$/, '.json');
     const transcriptData = transcripts.get(transcriptName);
     
-    // Just enrich with transcript data, preserve existing metadata
+    // Enrich the clip data received from BinViewer with transcript
     const enrichedClip = {
-      ...clipData,  // Keep all original data including metadata
+      ...clipData,  // Keep all the timing and file data from BinViewer
       transcript: transcriptData || null
     };
     
-    console.log('Adding clip to timeline:', {
-      original: clipData,
-      enriched: enrichedClip,
-      hasMetadata: !!clipData.metadata,
-      metadata: clipData.metadata
-    });
-    
     setTimelineClips(prevClips => [...prevClips, enrichedClip]);
   };
 
@@ -259,13 +240,6 @@ const handleChatMessage = (message) => {
               />
             </Box>
           </EditorLayout>
-          <ChatBot 
-  messages={chatMessages}
-  onSendMessage={handleChatMessage}
-  selectedBinClip={selectedBinClip}
-  transcriptData={selectedBinClip ? transcripts.get(selectedBinClip.name.replace(/\.[^/.]+$/, '.json')) : null}
-  onAddToTimeline={handleAddToTimeline} 
-/>
         </MainLayout>
 
         {/* Notifications */}
@@ -287,7 +261,4 @@ const handleChatMessage = (message) => {
   );
 }
 
-export default App;
-
-
-
+export default App;
\ No newline at end of file
diff --git a/src/components/Chatbot/Api.js b/src/components/Chatbot/Api.js
deleted file mode 100644
index 983591c..0000000
--- a/src/components/Chatbot/Api.js
+++ /dev/null
@@ -1,51 +0,0 @@
-//src/components/Chatbot/Api.js
-import axios from 'axios';
-
-const PROCESS_URL = process.env.REACT_APP_PROCESS_URL || 'http://74.235.95.232:8004';
-const TRANSCRIPT_API_URL = 'http://74.235.95.232:5002/process_transcripts';
-
-export const sendToLLM = async (wordTimingJson, promptTemplate, userInput, task) => {
-  try {
-    const response = await axios.post(`${PROCESS_URL}/process_request`, {
-      text: wordTimingJson,
-      prompt_template: promptTemplate,
-      user_input: userInput,
-      task: task,
-    });
-    if (response.data && response.data.result) {
-      return response.data.result;
-    } else {
-      throw new Error('Invalid response format');
-    }
-  } catch (error) {
-    console.error('Error processing video content:', error);
-    if (error.response) {
-      console.error('Server responded with error:', error.response.data);
-      throw new Error(error.response.data.error || 'Server error');
-    } else if (error.request) {
-      console.error('No response received from server');
-      throw new Error('No response from server');
-    } else {
-      console.error('Error setting up request:', error.message);
-      throw error;
-    }
-  }
-};
-
-export const processTranscripts = async (editedTranscript) => {
-  try {
-    console.log('Sending request to process transcripts:');
-    console.log('Edited transcript:', editedTranscript);
-    const response = await axios.post(TRANSCRIPT_API_URL, {
-      edited_transcript: editedTranscript
-    });
-    console.log('Received response from server:', response.data);
-    return response.data;
-  } catch (error) {
-    console.error('Error processing transcripts:', error);
-    if (error.response) {
-      console.error('Server response:', error.response.data);
-    }
-    throw error;
-  }
-};
\ No newline at end of file
diff --git a/src/components/Chatbot/ChatBot.js b/src/components/Chatbot/ChatBot.js
deleted file mode 100644
index 86967aa..0000000
--- a/src/components/Chatbot/ChatBot.js
+++ /dev/null
@@ -1,328 +0,0 @@
-import React, { useState } from 'react';
-import { Box, TextField, Button, Select, MenuItem, FormControl, CircularProgress } from '@mui/material';
-import { promptTemplates } from './promptTemplates';
-import { sendToLLM } from './Api';
-
-const ChatBot = ({ 
-  onSendMessage, 
-  messages, 
-  selectedBinClip, 
-  transcriptData,
-  onAddToTimeline 
-}) => {
-  const [input, setInput] = useState('');
-  const [selectedTemplate, setSelectedTemplate] = useState('');
-  const [isLoading, setIsLoading] = useState(false);
-
-  const processAndAddToTimeline = async (text) => {
-    try {
-      if (!selectedBinClip) {
-        throw new Error('No video clip selected');
-      }
-  
-      // Parse and sort words chronologically
-      const words = text.split(' ')
-        .filter(w => w.includes('|'))
-        .map(word => {
-          const [text, start, end, speaker] = word.split('|');
-          if (!start || !end || isNaN(parseFloat(start)) || isNaN(parseFloat(end))) {
-            throw new Error('Invalid word timing format');
-          }
-          return {
-            text,
-            start: parseFloat(start),
-            end: parseFloat(end),
-            speaker
-          };
-        })
-        .sort((a, b) => a.start - b.start);
-  
-      if (words.length === 0) {
-        throw new Error('No valid words found in response');
-      }
-  
-      // Group into segments
-      const GAP_THRESHOLD = 0.5;
-      let segments = [];
-      let currentSegment = [words[0]];
-  
-      for (let i = 1; i < words.length; i++) {
-        const currentWord = words[i];
-        const lastWord = currentSegment[currentSegment.length - 1];
-        const gap = currentWord.start - lastWord.end;
-        
-        if (gap > GAP_THRESHOLD) {
-          segments.push(currentSegment);
-          currentSegment = [currentWord];
-        } else {
-          currentSegment.push(currentWord);
-        }
-      }
-      
-      if (currentSegment.length > 0) {
-        segments.push(currentSegment);
-      }
-  
-      // Create video element for metadata
-      const video = document.createElement('video');
-      video.src = URL.createObjectURL(selectedBinClip.file);
-  
-      video.addEventListener('loadedmetadata', () => {
-        // Keep track of timeline position for sequential placement
-        let currentTimelinePosition = 0;
-  
-        // Add each segment to timeline
-        segments.forEach((segment, index) => {
-          const timelineDuration = segment[segment.length - 1].end - segment[0].start;
-          const sourceStart = segment[0].start;
-          const sourceEnd = segment[segment.length - 1].end;
-          
-          const clipData = {
-            id: `clip-${Date.now()}-${index}`,
-            file: selectedBinClip.file,
-            name: selectedBinClip.file.name,
-            startTime: sourceStart,  // Original source timing
-            endTime: sourceEnd,      // Original source timing
-            duration: timelineDuration,
-            source: {
-              startTime: 0,
-              endTime: video.duration,
-              duration: video.duration
-            },
-            transcript: segment.map(word => word.text).join(' '),
-            // Update metadata for sequential timeline placement
-            metadata: {
-              timeline: {
-                start: currentTimelinePosition,  // Sequential position
-                end: currentTimelinePosition + timelineDuration,  // Sequential end
-                duration: timelineDuration,
-                track: 0
-              },
-              playback: {
-                start: sourceStart,  // Original timing for playback
-                end: sourceEnd,      // Original timing for playback
-                duration: timelineDuration
-              }
-            },
-            selectionInfo: {
-              words: segment,
-              timeRange: {
-                start: sourceStart,
-                end: sourceEnd
-              },
-              text: segment.map(word => word.text).join(' ')
-            }
-          };
-  
-          onAddToTimeline?.(clipData);
-  
-          // Update timeline position for next clip
-          currentTimelinePosition += timelineDuration;
-        });
-  
-        // Cleanup
-        video.src = '';
-        URL.revokeObjectURL(video.src);
-      });
-  
-  
-      // Success message
-      onSendMessage({
-        text: `Successfully added ${segments.length} clip${segments.length > 1 ? 's' : ''} to timeline`,
-        sender: 'bot',
-        isSuccess: true
-      });
-  
-    } catch (error) {
-      console.error('Error processing segments:', error);
-      onSendMessage({
-        text: `Error: ${error.message}. Please try again with a different prompt.`,
-        sender: 'bot',
-        isError: true
-      });
-    }
-  };
-
-  const handleSubmit = async (e) => {
-    e.preventDefault();
-    if (input.trim() && selectedTemplate) {
-      setIsLoading(true);
-      try {
-        onSendMessage({
-          text: input,
-          sender: 'user',
-          template: selectedTemplate
-        });
-
-        const templateContent = promptTemplates.find(t => t.name === selectedTemplate)?.template;
-        if (!templateContent) {
-          throw new Error('Template not found');
-        }
-
-        const wordTimingJson = transcriptData ? JSON.stringify(transcriptData) : '';
-        
-        const llmResponse = await sendToLLM(
-          wordTimingJson,
-          templateContent,
-          input,
-          'chat'
-        );
-
-        // Process response and add to timeline
-        await processAndAddToTimeline(llmResponse);
-
-        setInput('');
-      } catch (error) {
-        console.error('Chat error:', error);
-        onSendMessage({
-          text: `Error: ${error.message}. Please try a different prompt.`,
-          sender: 'bot',
-          isError: true
-        });
-      } finally {
-        setIsLoading(false);
-      }
-    }
-  };
-
-  return (
-    <Box sx={{
-      position: 'fixed',
-      bottom: 0,
-      left: 0,
-      width: '240px',
-      height: '300px',
-      borderTop: 1,
-      borderRight: 1,
-      borderColor: 'divider',
-      backgroundColor: 'background.paper',
-      display: 'flex',
-      flexDirection: 'column',
-      zIndex: 1000,
-    }}>
-      {/* Header */}
-      <Box sx={{ 
-        p: 1, 
-        borderBottom: 1, 
-        borderColor: 'divider',
-        backgroundColor: 'background.default',
-        display: 'flex',
-        justifyContent: 'space-between',
-        alignItems: 'center'
-      }}>
-        <Box sx={{ fontSize: '16px', fontWeight: 'bold' }}>
-          Chatbot
-        </Box>
-        {isLoading && <CircularProgress size={20} />}
-      </Box>
-
-      {/* Messages Area */}
-      <Box 
-        sx={{ 
-          flex: 1,
-          overflow: 'auto',
-          p: 1,
-          backgroundColor: '#1e1e1e'
-        }}
-      >
-        {messages.map((msg, index) => (
-          <Box
-            key={index}
-            sx={{
-              p: 1,
-              mb: 1,
-              borderRadius: 1,
-              maxWidth: '85%',
-              wordBreak: 'break-word',
-              ...(msg.sender === 'user' ? {
-                ml: 'auto',
-                backgroundColor: '#0ea5e9',
-                color: 'white',
-              } : {
-                mr: 'auto',
-                backgroundColor: msg.isError ? '#ef4444' : 
-                               msg.isSuccess ? '#22c55e' : '#2d2d2d',
-                color: 'white',
-              })
-            }}
-          >
-            {msg.text}
-          </Box>
-        ))}
-      </Box>
-
-      {/* Input Area */}
-      <Box 
-        component="form" 
-        onSubmit={handleSubmit}
-        sx={{
-          p: 1,
-          display: 'flex',
-          flexDirection: 'column',
-          gap: 1,
-          borderTop: 1,
-          borderColor: 'divider',
-          backgroundColor: 'background.paper'
-        }}
-      >
-        <FormControl size="small" fullWidth>
-          <Select
-            value={selectedTemplate}
-            onChange={(e) => setSelectedTemplate(e.target.value)}
-            displayEmpty
-            disabled={isLoading}
-            sx={{
-              backgroundColor: '#2d2d2d',
-              '& .MuiOutlinedInput-notchedOutline': {
-                borderColor: '#404040',
-              },
-              '&:hover .MuiOutlinedInput-notchedOutline': {
-                borderColor: '#505050',
-              },
-            }}
-          >
-            <MenuItem value="">Select a template</MenuItem>
-            {promptTemplates.map(template => (
-              <MenuItem key={template.name} value={template.name}>
-                {template.name}
-              </MenuItem>
-            ))}
-          </Select>
-        </FormControl>
-        
-        <Box sx={{ display: 'flex', gap: 1 }}>
-          <TextField
-            size="small"
-            value={input}
-            onChange={(e) => setInput(e.target.value)}
-            placeholder="Type your message..."
-            disabled={isLoading}
-            fullWidth
-            sx={{
-              '& .MuiOutlinedInput-root': {
-                backgroundColor: '#2d2d2d',
-                '& fieldset': {
-                  borderColor: '#404040',
-                },
-                '&:hover fieldset': {
-                  borderColor: '#505050',
-                },
-              },
-            }}
-          />
-          <Button 
-            type="submit"
-            variant="contained" 
-            color="primary"
-            disabled={!input.trim() || !selectedTemplate || isLoading}
-            sx={{ minWidth: '60px' }}
-          >
-            Send
-          </Button>
-        </Box>
-      </Box>
-    </Box>
-  );
-};
-
-export default ChatBot;
\ No newline at end of file
diff --git a/src/components/Chatbot/ChatBot.module.css b/src/components/Chatbot/ChatBot.module.css
deleted file mode 100644
index 651ab76..0000000
--- a/src/components/Chatbot/ChatBot.module.css
+++ /dev/null
@@ -1,97 +0,0 @@
-.chatbot {
-  display: flex;
-  flex-direction: column;
-  height: 100%;
-  background-color: #f0f0f0;
-  border-radius: 8px;
-  overflow: hidden;
-}
-
-.chat-messages {
-  flex-grow: 1;
-  overflow-y: auto;
-  padding: 16px;
-  display: flex;
-  flex-direction: column;
-}
-
-.message {
-  max-width: 70%;
-  margin-bottom: 12px;
-  padding: 8px 12px;
-  border-radius: 18px;
-  font-size: 14px;
-  line-height: 1.4;
-}
-
-.message.user {
-  align-self: flex-end;
-  background-color: #007bff;
-  color: white;
-}
-
-.message.bot {
-  align-self: flex-start;
-  background-color: #e9e9eb;
-  color: black;
-}
-
-.chat-input-form {
-  display: flex;
-  padding: 16px;
-  background-color: white;
-}
-
-.chat-input {
-  flex-grow: 1;
-  padding: 8px 12px;
-  border: 1px solid #ccc;
-  border-radius: 20px;
-  font-size: 14px;
-}
-
-.chat-submit-button {
-  margin-left: 8px;
-  padding: 8px 16px;
-  background-color: #007bff;
-  color: white;
-  border: none;
-  border-radius: 20px;
-  font-size: 14px;
-  cursor: pointer;
-}
-
-.chat-submit-button:disabled {
-  background-color: #ccc;
-  cursor: not-allowed;
-}
-
-.chatbot-editor {
-  margin-top: 16px;
-  padding: 16px;
-  background-color: white;
-  border-radius: 8px;
-}
-
-.editable-response {
-  min-height: 100px;
-  max-height: 300px;
-  overflow-y: auto;
-  border: 1px solid #ccc;
-  padding: 10px;
-  white-space: pre-wrap;
-  background-color: #f9f9f9;
-  border-radius: 4px;
-}
-
-.debug-info {
-  margin-top: 16px;
-  padding: 16px;
-  background-color: #f0f0f0;
-  border-radius: 8px;
-}
-
-.debug-info pre {
-  white-space: pre-wrap;
-  word-break: break-all;
-}
\ No newline at end of file
diff --git a/src/components/Chatbot/ChatbotResponseViewer.js b/src/components/Chatbot/ChatbotResponseViewer.js
deleted file mode 100644
index 1142a92..0000000
--- a/src/components/Chatbot/ChatbotResponseViewer.js
+++ /dev/null
@@ -1,35 +0,0 @@
-import React from 'react';
-
-const ChatbotResponseViewer = ({ response }) => {
-  const handleCopy = (e) => {
-    e.preventDefault();
-    const selection = window.getSelection();
-    const selectedText = selection.toString();
-    
-    if (selectedText) {
-      e.clipboardData.setData('text/plain', selectedText);
-      console.log('Copied text:', selectedText);
-    }
-  };
-
-  return (
-    <div className="chatbot-response-viewer">
-      <h3>Chatbot Response</h3>
-      <div
-        onCopy={handleCopy}
-        style={{
-          minHeight: '100px',
-          maxHeight: '300px',
-          overflowY: 'auto',
-          border: '1px solid #ccc',
-          padding: '10px',
-          whiteSpace: 'pre-wrap'
-        }}
-      >
-        {response}
-      </div>
-    </div>
-  );
-};
-
-export default ChatbotResponseViewer;
\ No newline at end of file
diff --git a/src/components/Chatbot/promptTemplates.js b/src/components/Chatbot/promptTemplates.js
deleted file mode 100644
index a99b9ad..0000000
--- a/src/components/Chatbot/promptTemplates.js
+++ /dev/null
@@ -1,13 +0,0 @@
-export const promptTemplates = [
-  {
-    name: "Edit Transcript",
-    template: `
-You are a video editor. Edit the provided transcript according to this request: {user_input}
-Focus on maintaining word-level timing and speaker information.
-Original Transcript JSON: {input_json}
-Respond with a string where each word is "word|start|end|speaker", separated by spaces.
-Ensure the edited transcript follows the user's instructions, maintains chronological order, and preserves timing and speaker info.
-Remove excluded words/segments. Adjust positions if order changes.
-    `
-  }
-];
diff --git a/src/components/Layout/ChatbotLayout.js b/src/components/Layout/ChatbotLayout.js
deleted file mode 100644
index afed165..0000000
--- a/src/components/Layout/ChatbotLayout.js
+++ /dev/null
@@ -1,76 +0,0 @@
-import React from 'react';
-import { Box, TextField, Button } from '@mui/material';
-
-const ChatbotLayout = () => {
-  return (
-    <Box sx={{
-      position: 'fixed',
-      bottom: 0,
-      left: 0,
-      width: '240px', // Match sidebar width
-      height: '300px',
-      borderTop: 1,
-      borderRight: 1,
-      borderColor: 'divider',
-      backgroundColor: 'background.paper',
-      display: 'flex',
-      flexDirection: 'column',
-      zIndex: 1000,
-    }}>
-      <Box sx={{ 
-        p: 1, 
-        borderBottom: 1, 
-        borderColor: 'divider',
-        backgroundColor: 'background.default'
-      }}>
-        <Box sx={{ fontSize: '16px', fontWeight: 'bold' }}>
-          Chatbot
-        </Box>
-      </Box>
-
-      <Box sx={{ 
-        flex: 1,
-        overflow: 'auto',
-        p: 1,
-        backgroundColor: '#1e1e1e'
-      }}>
-        {/* Chat messages would go here */}
-      </Box>
-
-      <Box sx={{
-        p: 1,
-        display: 'flex',
-        gap: 1,
-        borderTop: 1,
-        borderColor: 'divider',
-      }}>
-        <TextField
-          size="small"
-          placeholder="Type your message..."
-          variant="outlined"
-          fullWidth
-          sx={{
-            '& .MuiOutlinedInput-root': {
-              backgroundColor: '#2d2d2d',
-              '& fieldset': {
-                borderColor: '#404040',
-              },
-              '&:hover fieldset': {
-                borderColor: '#505050',
-              },
-            },
-          }}
-        />
-        <Button 
-          variant="contained" 
-          color="primary"
-          sx={{ minWidth: '60px' }}
-        >
-          Send
-        </Button>
-      </Box>
-    </Box>
-  );
-};
-
-export default ChatbotLayout;
\ No newline at end of file
diff --git a/src/components/Timeline/index.js b/src/components/Timeline/index.js
index 738ccc4..6cd2a52 100644
--- a/src/components/Timeline/index.js
+++ b/src/components/Timeline/index.js
@@ -251,59 +251,48 @@ onClipsChange(updatedClips);
 }, [clips, onClipsChange]);
 
   // Handle general changes
-  // Update the handleChange callback in Timeline component
-const handleChange = useCallback((newEditorData) => {
-  console.log('Timeline Changed:', newEditorData);
+  const handleChange = useCallback((newEditorData) => {
+    console.log('Timeline Changed:', newEditorData);
+    
+    if (!newEditorData?.actions) return;
   
-  if (!newEditorData?.actions) return;
-
-  const updatedClips = clips.map(clip => {
-    const action = newEditorData.actions.find(a => a.id === clip.id);
-    if (!action) return clip;
-
-    // Get the current metadata from the action data or initialize it
-    const actionData = action.data || {};
-    const metadata = actionData.metadata || {};
-    const timeline = metadata.timeline || {};
-    const playback = metadata.playback || {};
-
-    // Initialize timeline metadata if not present
-    const hasTimelineMetadata = Object.keys(timeline).length > 0;
-    const timelineStart = hasTimelineMetadata ? timeline.start : action.start;
-    const timelineEnd = hasTimelineMetadata ? timeline.end : action.end;
-    const timelineDuration = timelineEnd - timelineStart;
-
-    // Initialize playback metadata if not present
-    const hasPlaybackMetadata = Object.keys(playback).length > 0;
-    const playbackStart = hasPlaybackMetadata ? playback.start : clip.startTime;
-    const playbackEnd = hasPlaybackMetadata ? playback.end : clip.endTime;
-    const playbackDuration = playbackEnd - playbackStart;
-
-    return {
-      ...clip,
-      ...actionData,
-      startTime: playbackStart,
-      endTime: playbackEnd,
-      metadata: {
-        ...metadata,
-        timeline: {
-          start: timelineStart,
-          end: timelineEnd,
-          duration: timelineDuration,
-        },
-        playback: {
-          start: playbackStart,
-          end: playbackEnd,
-          duration: playbackDuration
+    const updatedClips = clips.map(clip => {
+      const action = newEditorData.actions.find(a => a.id === clip.id);
+      if (!action) return clip;
+  
+      // Get the current metadata from the action data
+      const actionData = action.data || {};
+      const metadata = actionData.metadata || {};
+      const timeline = metadata.timeline || {};
+      const playback = metadata.playback || {};
+  
+      // Calculate the current duration based on timeline
+      const timelineDuration = action.end - action.start;
+  
+      return {
+        ...clip,
+        ...actionData, // Include all action data updates
+        startTime: playback.start || clip.startTime,
+        endTime: playback.end || clip.endTime,
+        metadata: {
+          ...metadata,
+          timeline: {
+            ...timeline,
+            start: action.start,
+            end: action.end,
+            duration: timelineDuration,
+          },
+          playback: {
+            start: playback.start || clip.startTime,
+            end: playback.end || clip.endTime,
+            duration: playback.duration || (playback.end - playback.start)
+          }
         }
-      }
-    };
-  });
-
-  console.log('Updated clips with metadata:', updatedClips);
-  onClipsChange(updatedClips);
-}, [clips, onClipsChange]);
-
+      };
+    });
+  
+    onClipsChange(updatedClips);
+  }, [clips, onClipsChange]);
 
   // Timeline state export functionality
   const timelineState = {
diff --git a/src/components/Viewers/BinViewer.js b/src/components/Viewers/BinViewer.js
index acc38e3..f87b9e8 100644
--- a/src/components/Viewers/BinViewer.js
+++ b/src/components/Viewers/BinViewer.js
@@ -111,48 +111,24 @@ const BinViewer = ({ selectedClip, onAddToTimeline }) => {
     setPlaying(false);
   };
 
-  const handleAddToTimeline = () => {
+ const handleAddToTimeline = () => {
     if (!selectedClip || error) return;
-  
-    // Calculate initial timeline position (fallback to 0 if none exist)
-    const timelineStart = 0;  // This will be adjusted by App.js based on existing clips
-    const timelineDuration = range[1] - range[0];
-    const timelineEnd = timelineStart + timelineDuration;
-  
+
     const clipData = {
       id: `clip-${Date.now()}`, // Generate unique ID
       file: selectedClip.file,
       name: selectedClip.file.name,
       startTime: range[0],  // Start of trimmed section
       endTime: range[1],    // End of trimmed section
-      duration: timelineDuration,  // Duration of trimmed section
+      duration: range[1] - range[0],  // Duration of trimmed section
       source: {
         startTime: 0,
         endTime: duration,        // Full video duration from ReactPlayer
         duration: duration        // Full video duration
-      },
-      // Add initial metadata
-      metadata: {
-        timeline: {
-          start: timelineStart,
-          end: timelineEnd,
-          duration: timelineDuration,
-          track: 0 // Default to first track
-        },
-        playback: {
-          start: range[0],
-          end: range[1],
-          duration: timelineDuration
-        }
       }
     };
-  
-    console.log('Adding clip with metadata:', {
-      clip: clipData,
-      timeline: clipData.metadata.timeline,
-      playback: clipData.metadata.playback
-    });
-    
+
+    console.log('Adding clip with data:', clipData); // Let's see what we're passing
     onAddToTimeline?.(clipData);
   };
 
diff --git a/src/components/Viewers/TimelineViewerSection.js b/src/components/Viewers/TimelineViewerSection.js
index 4f6ca03..ad33f7b 100644
--- a/src/components/Viewers/TimelineViewerSection.js
+++ b/src/components/Viewers/TimelineViewerSection.js
@@ -50,7 +50,6 @@ const TimelineViewerSection = ({ clips, currentClip, transcript,timelineState })
           />
         ) : (
           <TimelineTranscriptViewer
-            key={clips.length} // Force refresh when clips array changes
             clips={clips}
             currentClip={currentClip}
             transcriptData={transcript}
diff --git a/src/components/Viewers/TranscriptViewer.js b/src/components/Viewers/TranscriptViewer.js
index e91f1c5..cefb29a 100644
--- a/src/components/Viewers/TranscriptViewer.js
+++ b/src/components/Viewers/TranscriptViewer.js
@@ -31,16 +31,6 @@ const TranscriptViewer = ({
     }
   }, [selectedClip]);
 
-  const handleWordSelection = useCallback((startWord, endWord, text) => {
-    setSelection({
-      start: startWord.start,
-      end: endWord.end,
-      text,
-      startWord,
-      endWord
-    });
-  }, []);
-
 
   const handleWordClick = useCallback((time) => {
     if (videoRef.current) {
@@ -52,30 +42,22 @@ const TranscriptViewer = ({
   const handleTextSelection = useCallback(() => {
     const selection = window.getSelection();
     if (!selection.rangeCount) return;
-  
+
     const range = selection.getRangeAt(0);
     const startNode = range.startContainer.parentNode;
     const endNode = range.endContainer.parentNode;
-  
+
     if (startNode.hasAttribute('data-time') && endNode.hasAttribute('data-time')) {
-      const startTime = parseFloat(startNode.getAttribute('data-time'));
-      const startEndTime = parseFloat(startNode.getAttribute('data-time-end'));
-      const endTime = parseFloat(endNode.getAttribute('data-time-end'));
-  
-      // Find the actual words from transcriptData
-      const startWord = transcriptData.transcription
-        .flatMap(item => item.words)
-        .find(word => word.start === startTime && word.end === startEndTime);
-  
-      const endWord = transcriptData.transcription
-        .flatMap(item => item.words)
-        .find(word => word.end === endTime);
-  
-      if (startWord && endWord) {
-        handleWordSelection(startWord, endWord, selection.toString());
-      }
+      const start = parseFloat(startNode.getAttribute('data-time'));
+      const end = parseFloat(endNode.getAttribute('data-time-end') || endNode.getAttribute('data-time'));
+      
+      setSelection({
+        start,
+        end,
+        text: selection.toString()
+      });
     }
-  }, [transcriptData, handleWordSelection]);
+  }, []);
 
   const handleAddToTimeline = useCallback(() => {
     if (!selection || !selectedClip) {
@@ -89,64 +71,32 @@ const TranscriptViewer = ({
   
     // Wait for metadata to load to get duration
     video.addEventListener('loadedmetadata', () => {
-      const timelineDuration = selection.end - selection.start;
-      
       const clipData = {
         id: `clip-${Date.now()}`,
         file: selectedClip.file,
         name: selectedClip.file.name,
         startTime: selection.start,
         endTime: selection.end,
-        duration: timelineDuration,
+        duration: selection.end - selection.start,
         source: {
           startTime: 0,
           endTime: video.duration,
           duration: video.duration
         },
-        transcript: selection.text,
-        // Add initial metadata
-        metadata: {
-          timeline: {
-            start: 0, // This will be adjusted by App.js
-            end: timelineDuration, // This will be adjusted by App.js
-            duration: timelineDuration,
-            track: 0 // Default to first track
-          },
-          playback: {
-            start: selection.start,
-            end: selection.end,
-            duration: timelineDuration
-          }
-        },
-        // Add selection info to help with transcript display
-        selectionInfo: {
-          text: selection.text,
-          startWord: selection.startWord,
-          endWord: selection.endWord,
-          timeRange: {
-            start: selection.start,
-            end: selection.end
-          }
-        }
+        transcript: selection.text
       };
   
       // Cleanup
       video.src = '';
       URL.revokeObjectURL(video.src);
   
-      console.log('Adding clip from transcript selection:', {
-        clipData,
-        selection,
-        timeline: clipData.metadata.timeline,
-        playback: clipData.metadata.playback
-      });
-  
+      console.log('Adding clip with data:', clipData);
       onAddToTimeline?.(clipData);
       setSelection(null);
     });
   
   }, [selection, selectedClip, onAddToTimeline]);
-  
+
 
 
   const renderTranscript = () => {
@@ -163,7 +113,7 @@ const TranscriptViewer = ({
         </Box>
       );
     }
-  
+
     return transcriptData.transcription.map((item, index) => (
       <Box key={`segment-${index}`} sx={{ mb: 2 }}>
         <Typography 
@@ -180,7 +130,6 @@ const TranscriptViewer = ({
               key={`word-${wordIndex}`}
               data-time={word.start}
               data-time-end={word.end}
-              data-word-data={JSON.stringify(word)} // Store full word data
               onClick={() => handleWordClick(word.start)}
               sx={{
                 cursor: 'pointer',
@@ -189,13 +138,8 @@ const TranscriptViewer = ({
                 transition: 'background-color 0.2s',
                 bgcolor: currentTime >= word.start && currentTime < word.end 
                   ? 'primary.main' 
-                  : selection?.start === word.start || selection?.end === word.end
-                  ? 'primary.dark'
-                  : selection?.start <= word.start && selection?.end >= word.end
-                  ? 'primary.light'
                   : 'transparent',
-                color: (currentTime >= word.start && currentTime < word.end) ||
-                      (selection?.start <= word.start && selection?.end >= word.end)
+                color: currentTime >= word.start && currentTime < word.end 
                   ? 'primary.contrastText' 
                   : 'inherit',
                 '&:hover': {
